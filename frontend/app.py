"""
æ•°æ®å¤„ç†Agentçš„Streamlitå‰ç«¯ç•Œé¢
æä¾›ç”¨æˆ·å‹å¥½çš„æ•°æ®ä¸Šä¼ ã€é…ç½®ã€å¤„ç†å’Œç»“æœå±•ç¤ºåŠŸèƒ½
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import base64
import json
import time
import io
import sys
import os
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main import process_dataframe, validate_data_only
from utils.config_validator import get_default_config, get_config_template


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†Agent",
    page_icon="ğŸ”„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    font-weight: bold;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 2rem;
}
.section-header {
    font-size: 1.5rem;
    font-weight: bold;
    color: #2e7d32;
    margin-top: 2rem;
    margin-bottom: 1rem;
}
.metric-card {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 0.5rem;
    border-left: 4px solid #1f77b4;
}
.success-message {
    background-color: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid #c3e6cb;
}
.error-message {
    background-color: #f8d7da;
    color: #721c24;
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid #f5c6cb;
}
.sidebar-radio {
    margin-bottom: 0.5rem;
}
.sidebar-radio > div {
    background-color: #f8f9fa;
    padding: 0.5rem;
    border-radius: 0.5rem;
    margin-bottom: 0.3rem;
}
.sidebar-radio > div:hover {
    background-color: #e9ecef;
    transition: background-color 0.2s;
}
.guide-text {
    font-size: 0.85rem;
    line-height: 1.4;
    color: #666;
}
.github-button {
    background-color: #24292e !important;
    color: white !important;
    padding: 8px 16px;
    border-radius: 6px;
    text-decoration: none !important;
    display: inline-block;
    font-size: 14px;
    font-weight: 500;
    box-shadow: 0 2px 4px rgba(0,0,0,0.15);
    transition: all 0.2s ease;
    border: none;
}
.github-button:hover {
    background-color: #0366d6 !important;
    color: white !important;
    text-decoration: none !important;
    transform: translateY(-1px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.2);
}
</style>
""", unsafe_allow_html=True)


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    
    # æ ‡é¢˜å’ŒGitHubé“¾æ¥
    col1, col2 = st.columns([4, 1])
    with col1:
        st.markdown('<h1 class="main-header">ğŸ”„ æ•°æ®å¤„ç†Agent</h1>', unsafe_allow_html=True)
    with col2:
        st.markdown("""
        <div style="text-align: right; margin-top: 20px;">
            <a href="https://github.com/lc708/begin.new_dataProcessAgent" target="_blank" class="github-button">
                ğŸ“ GitHubæºç 
            </a>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("åŸºäºMACoreæ¡†æ¶çš„æ™ºèƒ½æ•°æ®æ ‡å‡†åŒ–å’Œé¢„å¤„ç†Agent - powered by [begin.new](https://www.begin.new/)")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ åŠŸèƒ½å¯¼èˆª")
        st.markdown("---")
        
        # ä½¿ç”¨å•é€‰æŒ‰é’®æ›¿ä»£ä¸‹æ‹‰æ¡†ï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰é¡µé¢
        page_options = [
            "ğŸ”„ æ•°æ®ä¸Šä¼ ä¸å¤„ç†",
            "âš™ï¸ é…ç½®ç®¡ç†", 
            "ğŸ“‹ å¤„ç†å†å²",
            "ğŸ’» ç³»ç»ŸçŠ¶æ€"
        ]
        
        page_display = st.radio(
            "è¯·é€‰æ‹©åŠŸèƒ½æ¨¡å—ï¼š",
            page_options,
            index=0,
            label_visibility="collapsed"
        )
        
        # å»æ‰å›¾æ ‡ï¼Œåªä¿ç•™æ–‡å­—ç”¨äºåç»­åŒ¹é…
        page = page_display.split(" ", 1)[1] if " " in page_display else page_display
        
        st.markdown("---")
        
        # æ·»åŠ ä¸€äº›è¾…åŠ©ä¿¡æ¯
        st.markdown("### ğŸ“š å¿«é€ŸæŒ‡å—")
        st.markdown('<div class="guide-text">', unsafe_allow_html=True)
        st.markdown("""
        **ğŸ”„ æ•°æ®å¤„ç†**  
        ä¸Šä¼ æ–‡ä»¶ï¼Œé…ç½®å¤„ç†é€‰é¡¹ï¼ŒæŸ¥çœ‹ç»“æœ
        
        **âš™ï¸ é…ç½®ç®¡ç†**  
        ç®¡ç†é»˜è®¤é…ç½®å’Œè‡ªå®šä¹‰æ¨¡æ¿
        
        **ğŸ“‹ å¤„ç†å†å²**  
        æŸ¥çœ‹å†å²ä»»åŠ¡å’Œç»“æœ
        
        **ğŸ’» ç³»ç»ŸçŠ¶æ€**  
        ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶æ€
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # æ·»åŠ ç‰ˆæœ¬ä¿¡æ¯
        st.markdown("---")
        st.markdown("**ç‰ˆæœ¬ä¿¡æ¯**")
        st.caption("ğŸ”§ MACore Framework")
        st.caption("ğŸš€ FastAPI + Streamlit")
        st.caption("ğŸ¤– AI-Powered Processing")
    
    # è·¯ç”±åˆ°ä¸åŒé¡µé¢
    if page == "æ•°æ®ä¸Šä¼ ä¸å¤„ç†":
        data_processing_page()
    elif page == "é…ç½®ç®¡ç†":
        config_management_page()
    elif page == "å¤„ç†å†å²":
        processing_history_page()
    elif page == "ç³»ç»ŸçŠ¶æ€":
        system_status_page()


def data_processing_page():
    """æ•°æ®ä¸Šä¼ ä¸å¤„ç†é¡µé¢"""
    st.markdown('<h2 class="section-header">ğŸ“ æ•°æ®ä¸Šä¼ ä¸å¤„ç†</h2>', unsafe_allow_html=True)
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("1. æ•°æ®ä¸Šä¼ ")
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls', 'json'],
            help="æ”¯æŒCSVã€Excelå’ŒJSONæ ¼å¼çš„æ•°æ®æ–‡ä»¶"
        )
        
        if uploaded_file is not None:
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            st.success(f"å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            # è¯»å–å¹¶é¢„è§ˆæ•°æ®
            try:
                df = load_data(uploaded_file)
                
                st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
                
                # åŸºæœ¬ä¿¡æ¯
                col_info1, col_info2, col_info3 = st.columns(3)
                with col_info1:
                    st.metric("è¡Œæ•°", len(df))
                with col_info2:
                    st.metric("åˆ—æ•°", len(df.columns))
                with col_info3:
                    st.metric("ç¼ºå¤±å€¼", df.isnull().sum().sum())
                
                # æ•°æ®é¢„è§ˆè¡¨æ ¼
                st.dataframe(df.head(10), use_container_width=True)
                
                # æ•°æ®è´¨é‡å¿«é€Ÿæ£€æŸ¥
                if st.button("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥", type="secondary"):
                    with st.spinner("æ­£åœ¨æ£€æŸ¥æ•°æ®è´¨é‡..."):
                        validation_result = validate_data_only(df)
                        
                        if validation_result['success']:
                            st.success("æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆï¼")
                            
                            errors = validation_result.get('validation_errors', [])
                            warnings = validation_result.get('validation_warnings', [])
                            
                            if errors:
                                st.error(f"å‘ç° {len(errors)} ä¸ªé”™è¯¯:")
                                for error in errors:
                                    st.write(f"âŒ {error}")
                            
                            if warnings:
                                st.warning(f"å‘ç° {len(warnings)} ä¸ªè­¦å‘Š:")
                                for warning in warnings:
                                    st.write(f"âš ï¸ {warning}")
                            
                            if not errors and not warnings:
                                st.success("âœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œå¤„ç†")
                        else:
                            st.error(f"æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {validation_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
            except Exception as e:
                st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
                uploaded_file = None
    
    with col2:
        st.subheader("2. å¤„ç†é…ç½®")
        
        # é…ç½®é€‰é¡¹
        use_default_config = st.checkbox("ä½¿ç”¨é»˜è®¤é…ç½®", value=True)
        
        if use_default_config:
            config = get_default_config()
            st.info("ä½¿ç”¨ç³»ç»Ÿé»˜è®¤é…ç½®")
            
            # ä¸ºé»˜è®¤é…ç½®ä¹Ÿæ˜¾ç¤ºé…ç½®è¯´æ˜
            show_config_explanation = st.checkbox("ğŸ’¡ æŸ¥çœ‹é…ç½®è¯´æ˜", value=False, help="äº†è§£é»˜è®¤é…ç½®çš„å…·ä½“åŠŸèƒ½")
            if show_config_explanation:
                display_config_explanation(config)
        else:
            st.subheader("è‡ªå®šä¹‰é…ç½®")
            config = configure_processing_options()
        
        # æ˜¾ç¤ºå½“å‰é…ç½®
        with st.expander("æŸ¥çœ‹å½“å‰é…ç½®", expanded=False):
            st.json(config)
    
    # å¤„ç†æŒ‰é’®å’Œç»“æœ
    st.markdown('<h3 class="section-header">ğŸš€ å¼€å§‹å¤„ç†</h3>', unsafe_allow_html=True)
    
    if uploaded_file is not None:
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", type="primary", use_container_width=True):
            process_data_workflow(df, config, uploaded_file.name)
    else:
        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")


def get_config_explanations() -> Dict[str, Dict[str, str]]:
    """è·å–é…ç½®å‚æ•°çš„è¯¦ç»†è§£é‡Š"""
    return {
        "standardization": {
            "title": "ğŸ“‹ è¡¨ç»“æ„æ ‡å‡†åŒ–",
            "description": "ç»Ÿä¸€æ•°æ®è¡¨çš„ç»“æ„æ ¼å¼ï¼Œæé«˜æ•°æ®è´¨é‡å’Œä¸€è‡´æ€§",
            "enable_column_rename": "å¯ç”¨åˆ—åæ ‡å‡†åŒ–ï¼šå°†åˆ—åè½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆå¦‚snake_caseï¼‰ï¼Œä¾¿äºç¨‹åºå¤„ç†",
            "naming_convention": "åˆ—åå‘½åè§„èŒƒï¼š\nâ€¢ snake_case: user_name\nâ€¢ camelCase: userName\nâ€¢ PascalCase: UserName",
            "remove_duplicate_columns": "ç§»é™¤é‡å¤åˆ—ï¼šè‡ªåŠ¨åˆ é™¤å†…å®¹å®Œå…¨ç›¸åŒçš„é‡å¤åˆ—ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´",
            "remove_empty_columns": "ç§»é™¤ç©ºåˆ—ï¼šåˆ é™¤å®Œå…¨æ²¡æœ‰æ•°æ®çš„åˆ—ï¼Œæ¸…ç†æ— ç”¨å­—æ®µ",
            "auto_detect_types": "è‡ªåŠ¨ç±»å‹æ£€æµ‹ï¼šæ™ºèƒ½è¯†åˆ«æ¯åˆ—çš„æœ€ä½³æ•°æ®ç±»å‹ï¼ˆæ•°å€¼ã€æ–‡æœ¬ã€æ—¥æœŸç­‰ï¼‰",
            "custom_type_mapping": "è‡ªå®šä¹‰ç±»å‹æ˜ å°„ï¼šä¸ºç‰¹å®šåˆ—æŒ‡å®šæ•°æ®ç±»å‹ï¼Œè¦†ç›–è‡ªåŠ¨æ£€æµ‹ç»“æœ"
        },
        "missing_handling": {
            "title": "ğŸ”§ ç¼ºå¤±å€¼å¤„ç†",
            "description": "æ™ºèƒ½å¡«å……æˆ–å¤„ç†æ•°æ®ä¸­çš„ç©ºå€¼ï¼Œæé«˜æ•°æ®å®Œæ•´æ€§",
            "default_strategy": "é»˜è®¤å¡«å……ç­–ç•¥ï¼š\nâ€¢ mean: ç”¨å¹³å‡å€¼å¡«å……\nâ€¢ median: ç”¨ä¸­ä½æ•°å¡«å……\nâ€¢ mode: ç”¨ä¼—æ•°å¡«å……\nâ€¢ forward_fill: ç”¨å‰ä¸€ä¸ªå€¼å¡«å……\nâ€¢ backward_fill: ç”¨åä¸€ä¸ªå€¼å¡«å……\nâ€¢ drop: åˆ é™¤å«ç©ºå€¼çš„è¡Œ",
            "column_strategies": "åˆ—ç‰¹å®šç­–ç•¥ï¼šä¸ºä¸åŒåˆ—è®¾ç½®ä¸åŒçš„å¡«å……ç­–ç•¥",
            "custom_fill_values": "è‡ªå®šä¹‰å¡«å……å€¼ï¼šä¸ºç‰¹å®šåˆ—æŒ‡å®šå›ºå®šçš„å¡«å……å€¼",
            "missing_threshold": "ç¼ºå¤±ç‡é˜ˆå€¼ï¼šå½“åˆ—çš„ç¼ºå¤±ç‡è¶…è¿‡æ­¤å€¼æ—¶ï¼Œç›´æ¥åˆ é™¤è¯¥åˆ—ï¼ˆ0.9 = 90%ï¼‰"
        },
        "masking_rules": {
            "title": "ğŸ›¡ï¸ æ•°æ®è„±æ•è§„åˆ™",
            "description": "è‡ªåŠ¨è¯†åˆ«å’Œä¿æŠ¤æ•æ„Ÿä¿¡æ¯ï¼Œç¡®ä¿æ•°æ®éšç§å®‰å…¨",
            "enable_auto_detection": "å¯ç”¨æ™ºèƒ½æ£€æµ‹ï¼šä½¿ç”¨AIå’Œè§„åˆ™è‡ªåŠ¨è¯†åˆ«æ‰‹æœºå·ã€é‚®ç®±ã€å§“åç­‰æ•æ„Ÿå­—æ®µ",
            "default_strategy": "é»˜è®¤è„±æ•ç­–ç•¥ï¼š\nâ€¢ partial: éƒ¨åˆ†é®æ©(138****5678)\nâ€¢ hash: å“ˆå¸Œæ›¿æ¢(a1b2c3d4)\nâ€¢ random: éšæœºæ›¿æ¢\nâ€¢ remove: å®Œå…¨åˆ é™¤",
            "column_rules": "åˆ—ç‰¹å®šè§„åˆ™ï¼šä¸ºç‰¹å®šåˆ—è®¾ç½®ä¸“é—¨çš„è„±æ•ç­–ç•¥",
            "sensitivity_threshold": "æ•æ„Ÿåº¦é˜ˆå€¼ï¼šAIåˆ¤æ–­å­—æ®µæ•æ„Ÿæ€§çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.7 = 70%ï¼‰"
        },
        "feature_extraction": {
            "title": "ğŸ¯ ç‰¹å¾æå–",
            "description": "ä»åŸå§‹æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç»Ÿè®¡å’Œè®¡ç®—ç‰¹å¾ï¼Œä¸°å¯Œæ•°æ®ç»´åº¦",
            "enable_extraction": "å¯ç”¨ç‰¹å¾æå–ï¼šæ˜¯å¦æ‰§è¡Œç‰¹å¾å·¥ç¨‹æ­¥éª¤ï¼ˆé»˜è®¤å…³é—­ï¼‰",
            "extract_numeric_stats": "æ•°å€¼ç‰¹å¾ï¼šæå–ç»Ÿè®¡æŒ‡æ ‡ï¼ˆç»å¯¹å€¼ã€æ˜¯å¦ä¸ºç©ºç­‰ï¼‰",
            "extract_text_features": "æ–‡æœ¬ç‰¹å¾ï¼šæå–æ–‡æœ¬é•¿åº¦ã€è¯æ•°ã€æ˜¯å¦ä¸ºç©ºç­‰ç‰¹å¾",
            "extract_datetime_features": "æ—¶é—´ç‰¹å¾ï¼šæå–å¹´ã€æœˆã€æ˜ŸæœŸå‡ ç­‰æ—¶é—´ç›¸å…³ç‰¹å¾",
            "custom_features": "è‡ªå®šä¹‰ç‰¹å¾ï¼šæ·»åŠ ä¸šåŠ¡ç›¸å…³çš„ç‰¹æ®Šç‰¹å¾æå–è§„åˆ™"
        }
    }


def display_config_explanation(config: Dict[str, Any]):
    """æ˜¾ç¤ºé…ç½®è§£é‡Šå’Œæ“ä½œæ€»è§ˆ"""
    explanations = get_config_explanations()
    
    # é…ç½®å‚æ•°è¯´æ˜
    st.markdown("### âš™ï¸ å½“å‰é…ç½®è§£é‡Š")
    
    # è¡¨ç»“æ„æ ‡å‡†åŒ–
    with st.expander("ğŸ“‹ è¡¨ç»“æ„æ ‡å‡†åŒ–", expanded=False):
        st.info(explanations['standardization']['description'])
        if config['standardization']['enable_column_rename']:
            st.markdown(f"âœ… **åˆ—åæ ‡å‡†åŒ–**: {config['standardization']['naming_convention']}")
        if config['standardization']['auto_detect_types']:
            st.markdown("âœ… **è‡ªåŠ¨ç±»å‹æ£€æµ‹**: ä¼˜åŒ–æ•°æ®ç±»å‹ï¼ŒèŠ‚çœå†…å­˜")
    
    # ç¼ºå¤±å€¼å¤„ç†
    with st.expander("ğŸ”§ ç¼ºå¤±å€¼å¤„ç†", expanded=False):
        st.info(explanations['missing_handling']['description'])
        st.markdown(f"âœ… **é»˜è®¤ç­–ç•¥**: {config['missing_handling']['default_strategy']}")
        st.markdown(f"âœ… **ç¼ºå¤±ç‡é˜ˆå€¼**: {config['missing_handling']['missing_threshold']:.0%} (è¶…è¿‡æ­¤å€¼åˆ é™¤åˆ—)")
    
    # æ•°æ®è„±æ•
    with st.expander("ğŸ›¡ï¸ æ•°æ®è„±æ•è§„åˆ™", expanded=True):
        st.info(explanations['masking_rules']['description'])
        if config['masking_rules']['enable_auto_detection']:
            st.markdown("âœ… **AIæ™ºèƒ½æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ«æ•æ„Ÿå­—æ®µ")
            st.markdown(f"âœ… **æ•æ„Ÿåº¦é˜ˆå€¼**: {config['masking_rules']['sensitivity_threshold']:.1f}")
            st.markdown(f"âœ… **è„±æ•ç­–ç•¥**: {config['masking_rules']['default_strategy']}")
            
            # æ•æ„Ÿåº¦è°ƒæ•´å»ºè®®
            st.markdown("**ğŸ’¡ è°ƒæ•´è„±æ•å­—æ®µæ•°é‡ï¼š**")
            current_threshold = config['masking_rules']['sensitivity_threshold']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if current_threshold <= 0.6:
                    st.success("ğŸ”’ **é«˜å®‰å…¨**: æ›´å¤šå­—æ®µè¢«ä¿æŠ¤")
                else:
                    st.markdown("ğŸ”’ **é«˜å®‰å…¨**: é˜ˆå€¼ â‰¤ 0.6")
            
            with col2:
                if 0.6 < current_threshold <= 0.8:
                    st.success("âš–ï¸ **å¹³è¡¡æ¨¡å¼**: å½“å‰è®¾ç½®")
                else:
                    st.markdown("âš–ï¸ **å¹³è¡¡æ¨¡å¼**: é˜ˆå€¼ 0.6-0.8")
            
            with col3:
                if current_threshold > 0.8:
                    st.success("ğŸ“Š **é‡å¯ç”¨æ€§**: è¾ƒå°‘å­—æ®µè¢«è„±æ•")
                else:
                    st.markdown("ğŸ“Š **é‡å¯ç”¨æ€§**: é˜ˆå€¼ > 0.8")
        else:
            st.markdown("âŒ **è‡ªåŠ¨æ£€æµ‹å·²å…³é—­**: ä»…å¤„ç†æ˜ç¡®æŒ‡å®šçš„æ•æ„Ÿå­—æ®µ")
    
    # ç‰¹å¾æå–
    with st.expander("ğŸ¯ ç‰¹å¾æå–", expanded=False):
        st.info(explanations['feature_extraction']['description'])
        if config['feature_extraction']['enable_extraction']:
            st.markdown("âœ… **ç‰¹å¾æå–å·²å¯ç”¨**")
            features = []
            if config['feature_extraction']['extract_numeric_stats']:
                features.append("æ•°å€¼ç»Ÿè®¡ç‰¹å¾")
            if config['feature_extraction']['extract_text_features']:
                features.append("æ–‡æœ¬é•¿åº¦ç‰¹å¾")
            if config['feature_extraction']['extract_datetime_features']:
                features.append("æ—¶é—´ç›¸å…³ç‰¹å¾")
            if features:
                st.markdown(f"â€¢ {', '.join(features)}")
        else:
            st.markdown("âŒ **ç‰¹å¾æå–å·²å…³é—­**")
    
    # æ“ä½œæ€»è§ˆ
    st.markdown("---")
    st.markdown("### ğŸ“‹ å¤„ç†æµç¨‹é¢„è§ˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**å°†è¦æ‰§è¡Œçš„æ“ä½œï¼š**")
        operations = []
        
        operations.append("ğŸ” æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥")
        if config['standardization']['enable_column_rename']:
            operations.append(f"ğŸ“‹ åˆ—åæ ‡å‡†åŒ– ({config['standardization']['naming_convention']})")
        if config['standardization']['auto_detect_types']:
            operations.append("ğŸ”§ è‡ªåŠ¨æ•°æ®ç±»å‹ä¼˜åŒ–")
        
        operations.append(f"ğŸ› ï¸ ç¼ºå¤±å€¼å¡«å…… ({config['missing_handling']['default_strategy']})")
        
        if config['masking_rules']['enable_auto_detection']:
            operations.append("ğŸ¤– AIæ™ºèƒ½æ•æ„Ÿå­—æ®µæ£€æµ‹")
            operations.append(f"ğŸ›¡ï¸ æ•°æ®è„±æ• ({config['masking_rules']['default_strategy']})")
        
        if config['feature_extraction']['enable_extraction']:
            operations.append("ğŸ¯ ç‰¹å¾å·¥ç¨‹")
        
        operations.append("ğŸ“Š ç”Ÿæˆè´¨é‡æŠ¥å‘Š")
        
        for op in operations:
            st.markdown(f"â€¢ {op}")
    
    with col2:
        st.markdown("**é¢„æœŸæ•ˆæœï¼š**")
        effects = [
            "æ•°æ®æ ¼å¼ç»Ÿä¸€æ ‡å‡†åŒ–",
            "ç¼ºå¤±å€¼å¾—åˆ°å¦¥å–„å¤„ç†", 
            "æ•°æ®å®Œæ•´æ€§æ˜¾è‘—æé«˜"
        ]
        
        if config['masking_rules']['enable_auto_detection']:
            effects.extend([
                "æ•æ„Ÿä¿¡æ¯è‡ªåŠ¨è¯†åˆ«ä¿æŠ¤",
                "æ•°æ®éšç§å®‰å…¨åˆè§„"
            ])
        
        if config['feature_extraction']['enable_extraction']:
            effects.append("å¢åŠ æœ‰ä»·å€¼çš„è®¡ç®—ç‰¹å¾")
        
        effects.append("è·å¾—è¯¦ç»†çš„è´¨é‡åˆ†ææŠ¥å‘Š")
        
        for effect in effects:
            st.markdown(f"â€¢ {effect}")


def configure_processing_options() -> Dict[str, Any]:
    """é…ç½®å¤„ç†é€‰é¡¹"""
    config = get_default_config()
    
    # æ˜¾ç¤ºé…ç½®è¯´æ˜å¼€å…³
    show_help = st.checkbox("ğŸ’¡ æ˜¾ç¤ºé…ç½®è¯´æ˜", value=False, help="æ˜¾ç¤ºæ¯ä¸ªé…ç½®é¡¹çš„è¯¦ç»†è¯´æ˜")
    explanations = get_config_explanations() if show_help else {}
    
    # è¡¨ç»“æ„æ ‡å‡†åŒ–é…ç½®
    st.subheader("ğŸ“‹ è¡¨ç»“æ„æ ‡å‡†åŒ–")
    if show_help and 'standardization' in explanations:
        st.info(explanations['standardization']['description'])
    
    config['standardization']['enable_column_rename'] = st.checkbox(
        "å¯ç”¨åˆ—åæ ‡å‡†åŒ–", 
        value=config['standardization']['enable_column_rename'],
        help=explanations.get('standardization', {}).get('enable_column_rename', '')
    )
    
    if config['standardization']['enable_column_rename']:
        config['standardization']['naming_convention'] = st.selectbox(
            "åˆ—åå‘½åçº¦å®š",
            ["snake_case", "camelCase", "PascalCase"],
            index=0,
            help=explanations.get('standardization', {}).get('naming_convention', '')
        )
    
    config['standardization']['auto_detect_types'] = st.checkbox(
        "è‡ªåŠ¨æ£€æµ‹æ•°æ®ç±»å‹",
        value=config['standardization']['auto_detect_types'],
        help=explanations.get('standardization', {}).get('auto_detect_types', '')
    )
    
    # ç¼ºå¤±å€¼å¤„ç†é…ç½®
    st.subheader("ğŸ”§ ç¼ºå¤±å€¼å¤„ç†")
    if show_help and 'missing_handling' in explanations:
        st.info(explanations['missing_handling']['description'])
    
    config['missing_handling']['default_strategy'] = st.selectbox(
        "é»˜è®¤å¡«å……ç­–ç•¥",
        ["mean", "median", "mode", "forward_fill", "backward_fill", "drop"],
        index=0,
        help=explanations.get('missing_handling', {}).get('default_strategy', '')
    )
    
    config['missing_handling']['missing_threshold'] = st.slider(
        "ç¼ºå¤±ç‡é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤å€¼åˆ é™¤åˆ—ï¼‰",
        0.0, 1.0, 
        value=config['missing_handling']['missing_threshold'],
        step=0.1,
        help=explanations.get('missing_handling', {}).get('missing_threshold', '')
    )
    
    # æ•°æ®è„±æ•é…ç½®
    st.subheader("ğŸ”’ æ•°æ®è„±æ•")
    if show_help and 'masking_rules' in explanations:
        st.info(explanations['masking_rules']['description'])
    
    config['masking_rules']['enable_auto_detection'] = st.checkbox(
        "å¯ç”¨æ•æ„Ÿå­—æ®µè‡ªåŠ¨æ£€æµ‹",
        value=config['masking_rules']['enable_auto_detection'],
        help=explanations.get('masking_rules', {}).get('enable_auto_detection', '')
    )
    
    if config['masking_rules']['enable_auto_detection']:
        config['masking_rules']['sensitivity_threshold'] = st.slider(
            "æ•æ„Ÿæ€§æ£€æµ‹é˜ˆå€¼",
            0.0, 1.0,
            value=config['masking_rules']['sensitivity_threshold'],
            step=0.1,
            help=explanations.get('masking_rules', {}).get('sensitivity_threshold', '')
        )
        
        # æ˜¾ç¤ºLLMè°ƒç”¨è¯´æ˜
        if show_help:
            st.markdown("**ğŸ¤– AIæ™ºèƒ½æ£€æµ‹è¯´æ˜**ï¼š")
            st.markdown("å½“å¯ç”¨è‡ªåŠ¨æ£€æµ‹æ—¶ï¼Œç³»ç»Ÿä¼šï¼š")
            st.markdown("1. é¦–å…ˆä½¿ç”¨è§„åˆ™æ£€æµ‹ï¼ˆåŸºäºåˆ—åå’Œæ•°æ®æ ¼å¼ï¼‰")
            st.markdown("2. å¯¹ä¸ç¡®å®šçš„å­—æ®µè°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ")
            st.markdown("3. ç»“åˆä¸¤ç§æ–¹æ³•çš„ç»“æœåšæœ€ç»ˆå†³ç­–")
    
    config['masking_rules']['default_strategy'] = st.selectbox(
        "é»˜è®¤è„±æ•ç­–ç•¥",
        ["partial", "hash", "random", "remove"],
        index=0,
        help=explanations.get('masking_rules', {}).get('default_strategy', '')
    )
    
    # ç‰¹å¾æå–é…ç½®
    st.subheader("ğŸ¯ ç‰¹å¾æå–")
    if show_help and 'feature_extraction' in explanations:
        st.info(explanations['feature_extraction']['description'])
    
    config['feature_extraction']['enable_extraction'] = st.checkbox(
        "å¯ç”¨ç‰¹å¾æå–",
        value=config['feature_extraction']['enable_extraction'],
        help=explanations.get('feature_extraction', {}).get('enable_extraction', '')
    )
    
    if config['feature_extraction']['enable_extraction']:
        config['feature_extraction']['extract_numeric_stats'] = st.checkbox(
            "æå–æ•°å€¼ç»Ÿè®¡ç‰¹å¾",
            value=config['feature_extraction']['extract_numeric_stats'],
            help=explanations.get('feature_extraction', {}).get('extract_numeric_stats', '')
        )
        
        config['feature_extraction']['extract_text_features'] = st.checkbox(
            "æå–æ–‡æœ¬ç‰¹å¾",
            value=config['feature_extraction']['extract_text_features'],
            help=explanations.get('feature_extraction', {}).get('extract_text_features', '')
        )
        
        config['feature_extraction']['extract_datetime_features'] = st.checkbox(
            "æå–æ—¶é—´ç‰¹å¾",
            value=config['feature_extraction']['extract_datetime_features'],
            help=explanations.get('feature_extraction', {}).get('extract_datetime_features', '')
        )
    
    # é…ç½®æ€»è§ˆ
    if show_help:
        st.markdown("---")
        st.subheader("ğŸ“‹ å½“å‰é…ç½®æ€»è§ˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**å°†è¦æ‰§è¡Œçš„æ“ä½œï¼š**")
            operations = []
            
            # è¡¨ç»“æ„æ ‡å‡†åŒ–
            if config['standardization']['enable_column_rename']:
                operations.append(f"ğŸ“‹ åˆ—åæ ‡å‡†åŒ– ({config['standardization']['naming_convention']})")
            if config['standardization']['auto_detect_types']:
                operations.append("ğŸ” è‡ªåŠ¨æ•°æ®ç±»å‹æ£€æµ‹")
            
            # ç¼ºå¤±å€¼å¤„ç†
            operations.append(f"ğŸ”§ ç¼ºå¤±å€¼å¡«å…… ({config['missing_handling']['default_strategy']})")
            if config['missing_handling']['missing_threshold'] < 1.0:
                operations.append(f"ğŸ—‘ï¸ åˆ é™¤é«˜ç¼ºå¤±ç‡åˆ— (>{config['missing_handling']['missing_threshold']:.0%})")
            
            # æ•°æ®è„±æ•
            if config['masking_rules']['enable_auto_detection']:
                operations.append("ğŸ›¡ï¸ AIæ™ºèƒ½æ•æ„Ÿå­—æ®µæ£€æµ‹")
                operations.append(f"ğŸ”’ æ•°æ®è„±æ• ({config['masking_rules']['default_strategy']})")
            
            # ç‰¹å¾æå–
            if config['feature_extraction']['enable_extraction']:
                operations.append("ğŸ¯ ç‰¹å¾å·¥ç¨‹")
            
            operations.append("ğŸ“Š ç”Ÿæˆè´¨é‡æŠ¥å‘Š")
            
            for op in operations:
                st.markdown(f"â€¢ {op}")
        
        with col2:
            st.markdown("**é¢„æœŸæ•ˆæœï¼š**")
            effects = []
            
            if config['standardization']['enable_column_rename']:
                effects.append("åˆ—åæ ¼å¼ç»Ÿä¸€ï¼Œä¾¿äºç¨‹åºå¤„ç†")
            if config['standardization']['auto_detect_types']:
                effects.append("æ•°æ®ç±»å‹ä¼˜åŒ–ï¼ŒèŠ‚çœå†…å­˜")
            
            effects.append("ç¼ºå¤±å€¼å‡å°‘ï¼Œæ•°æ®å®Œæ•´æ€§æé«˜")
            
            if config['masking_rules']['enable_auto_detection']:
                effects.append("æ•æ„Ÿä¿¡æ¯è‡ªåŠ¨è¯†åˆ«å’Œä¿æŠ¤")
                effects.append("æ•°æ®éšç§å®‰å…¨å¾—åˆ°ä¿éšœ")
            
            if config['feature_extraction']['enable_extraction']:
                effects.append("å¢åŠ æœ‰ç”¨çš„è®¡ç®—ç‰¹å¾")
            
            effects.append("è·å¾—è¯¦ç»†çš„æ•°æ®è´¨é‡åˆ†æ")
            
            for effect in effects:
                st.markdown(f"â€¢ {effect}")
    
    return config


def process_data_workflow(df: pd.DataFrame, config: Dict[str, Any], filename: str):
    """å¤„ç†æ•°æ®å·¥ä½œæµ"""
    # åˆ›å»ºå¤„ç†è¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("æ­£åœ¨åˆå§‹åŒ–å¤„ç†æµç¨‹...")
        progress_bar.progress(10)
        
        # å¤„ç†æ•°æ®
        status_text.text("æ­£åœ¨å¤„ç†æ•°æ®...")
        progress_bar.progress(50)
        
        result = process_dataframe(df, config, file_info={'filename': filename})
        
        progress_bar.progress(100)
        
        if result['success']:
            status_text.text("å¤„ç†å®Œæˆï¼")
            
            # æ˜¾ç¤ºå¤„ç†ç»“æœ
            display_processing_results(result)
            
            # ä¿å­˜ç»“æœåˆ°session state
            st.session_state['last_result'] = result
            
        else:
            st.error(f"å¤„ç†å¤±è´¥: {result['error']}")
            
            # æ˜¾ç¤ºå¤„ç†æ—¥å¿—
            if 'processing_log' in result:
                st.subheader("å¤„ç†æ—¥å¿—")
                for log_entry in result['processing_log']:
                    if log_entry.get('status') == 'failed':
                        st.error(f"âŒ {log_entry.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    else:
                        st.info(f"â„¹ï¸ {log_entry.get('message', 'æ­¥éª¤å®Œæˆ')}")
        
    except Exception as e:
        st.error(f"å¤„ç†å¼‚å¸¸: {str(e)}")
    finally:
        progress_bar.empty()
        status_text.empty()


def display_processing_results(result: Dict[str, Any]):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    st.markdown('<h3 class="section-header">ğŸ“Š å¤„ç†ç»“æœ</h3>', unsafe_allow_html=True)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["å¤„ç†åæ•°æ®", "è´¨é‡æŠ¥å‘Š", "è„±æ•ä¿¡æ¯", "å¤„ç†æ—¥å¿—", "æ•°æ®å¯¼å‡º"])
    
    with tab1:
        st.subheader("å¤„ç†åæ•°æ®")
        processed_data = result.get('processed_data')
        
        if processed_data is not None:
            # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶è½¬æ¢ä¸ºDataFrame
            if isinstance(processed_data, dict) and 'data' in processed_data:
                # ä»APIè¿”å›çš„å­—å…¸æ ¼å¼é‡å»ºDataFrame
                processed_df = pd.DataFrame(processed_data['data'])
                shape = processed_data.get('shape', (len(processed_df), len(processed_df.columns)))
            elif isinstance(processed_data, pd.DataFrame):
                # ç›´æ¥æ˜¯DataFrame
                processed_df = processed_data
                shape = processed_df.shape
            else:
                st.error("æœªçŸ¥çš„æ•°æ®æ ¼å¼")
                return
            
            # æ•°æ®ç»Ÿè®¡
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("è¡Œæ•°", shape[0])
            with col2:
                st.metric("åˆ—æ•°", shape[1])
            with col3:
                st.metric("ç¼ºå¤±å€¼", processed_df.isnull().sum().sum())
            with col4:
                st.metric("å†…å­˜ä½¿ç”¨", f"{processed_df.memory_usage(deep=True).sum() / 1024:.1f} KB")
            
            # æ•°æ®é¢„è§ˆ
            st.dataframe(processed_df, use_container_width=True)
        else:
            st.warning("æ²¡æœ‰å¤„ç†åçš„æ•°æ®")
    
    with tab2:
        st.subheader("æ•°æ®è´¨é‡æŠ¥å‘Š")
        
        # æ˜¾ç¤ºæ–‡æœ¬æŠ¥å‘Š
        text_report = result.get('text_report', '')
        if text_report:
            st.text_area("è´¨é‡æŠ¥å‘Š", text_report, height=300)
        
        # æ˜¾ç¤ºè´¨é‡æŒ‡æ ‡å›¾è¡¨
        quality_report = result.get('quality_report', {})
        if quality_report:
            display_quality_charts(quality_report)
    
    with tab3:
        st.subheader("æ•°æ®è„±æ•ä¿¡æ¯")
        masked_columns = result.get('masked_columns', [])
        
        if masked_columns:
            st.success(f"æˆåŠŸè„±æ• {len(masked_columns)} ä¸ªæ•æ„Ÿå­—æ®µ")
            
            for masked_col in masked_columns:
                with st.expander(f"å­—æ®µ: {masked_col['column']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**æ•æ„Ÿç±»å‹**: {masked_col['type']}")
                        st.write(f"**è„±æ•ç­–ç•¥**: {masked_col['strategy']}")
                    
                    with col2:
                        preview = masked_col.get('preview', {})
                        if preview:
                            st.write("**è„±æ•é¢„è§ˆ**:")
                            for orig, masked in zip(preview.get('original', []), preview.get('masked', [])):
                                st.write(f"{orig} â†’ {masked}")
        else:
            st.info("æœªæ£€æµ‹åˆ°éœ€è¦è„±æ•çš„æ•æ„Ÿå­—æ®µ")
    
    with tab4:
        st.subheader("å¤„ç†æ—¥å¿—")
        processing_log = result.get('processing_log', [])
        
        for log_entry in processing_log:
            status = log_entry.get('status', 'unknown')
            message = log_entry.get('message', 'æ— æ¶ˆæ¯')
            
            if status == 'success':
                st.success(f"âœ… {message}")
            elif status == 'failed':
                st.error(f"âŒ {message}")
            else:
                st.info(f"â„¹ï¸ {message}")
    
    with tab5:
        st.subheader("æ•°æ®å¯¼å‡º")
        processed_data = result.get('processed_data')
        
        if processed_data is not None:
            # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶è½¬æ¢ä¸ºDataFrame
            if isinstance(processed_data, dict) and 'data' in processed_data:
                # ä»APIè¿”å›çš„å­—å…¸æ ¼å¼é‡å»ºDataFrame
                processed_df = pd.DataFrame(processed_data['data'])
            elif isinstance(processed_data, pd.DataFrame):
                # ç›´æ¥æ˜¯DataFrame
                processed_df = processed_data
            else:
                st.error("æœªçŸ¥çš„æ•°æ®æ ¼å¼ï¼Œæ— æ³•å¯¼å‡º")
                return
            
            # å¯¼å‡ºæ ¼å¼é€‰æ‹©
            export_format = st.selectbox("é€‰æ‹©å¯¼å‡ºæ ¼å¼", ["CSV", "Excel", "JSON"])
            
            # ç›´æ¥æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼Œä¸ä½¿ç”¨ä¸­é—´æŒ‰é’®
            st.markdown("### ğŸ“¥ ä¸‹è½½å¤„ç†åæ•°æ®")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if export_format == "CSV":
                    csv_data = processed_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“„ ä¸‹è½½CSVæ–‡ä»¶",
                        data=csv_data,
                        file_name="processed_data.csv",
                        mime="text/csv",
                        type="primary"
                    )
            
            with col2:
                if export_format == "Excel":
                    buffer = io.BytesIO()
                    processed_df.to_excel(buffer, index=False)
                    st.download_button(
                        label="ğŸ“Š ä¸‹è½½Excelæ–‡ä»¶",
                        data=buffer.getvalue(),
                        file_name="processed_data.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        type="primary"
                    )
            
            with col3:
                if export_format == "JSON":
                    json_data = processed_df.to_json(orient='records', force_ascii=False)
                    st.download_button(
                        label="ğŸ“‹ ä¸‹è½½JSONæ–‡ä»¶",
                        data=json_data,
                        file_name="processed_data.json",
                        mime="application/json",
                        type="primary"
                    )
        else:
            st.warning("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")


def display_quality_charts(quality_report: Dict[str, Any]):
    """æ˜¾ç¤ºè´¨é‡æŒ‡æ ‡å›¾è¡¨"""
    # è´¨é‡å¾—åˆ†å¯¹æ¯”
    scores = quality_report.get('data_quality_score', {})
    if scores:
        # åˆ›å»ºå¾—åˆ†å¯¹æ¯”å›¾
        metrics = ['completeness', 'consistency', 'overall']
        original_scores = [scores.get(metric, {}).get('original', 0) for metric in metrics]
        processed_scores = [scores.get(metric, {}).get('processed', 0) for metric in metrics]
        
        fig = go.Figure(data=[
            go.Bar(name='å¤„ç†å‰', x=metrics, y=original_scores),
            go.Bar(name='å¤„ç†å', x=metrics, y=processed_scores)
        ])
        
        fig.update_layout(
            title='æ•°æ®è´¨é‡å¾—åˆ†å¯¹æ¯”',
            xaxis_title='è´¨é‡æŒ‡æ ‡',
            yaxis_title='å¾—åˆ† (%)',
            barmode='group'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # ç¼ºå¤±æ•°æ®åˆ†æ
    missing_data = quality_report.get('missing_data', {})
    if missing_data:
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                "ç¼ºå¤±å€¼å‡å°‘",
                f"{missing_data.get('improvement', {}).get('missing_reduction', 0)} ä¸ª",
                delta=f"{missing_data.get('improvement', {}).get('rate_improvement', 0):.2f}%"
            )
        
        with col2:
            original_rate = missing_data.get('original', {}).get('missing_rate', 0)
            processed_rate = missing_data.get('processed', {}).get('missing_rate', 0)
            st.metric(
                "ç¼ºå¤±ç‡",
                f"{processed_rate:.2f}%",
                delta=f"{processed_rate - original_rate:.2f}%"
            )





def config_management_page():
    """é…ç½®ç®¡ç†é¡µé¢"""
    st.markdown('<h2 class="section-header">âš™ï¸ é…ç½®ç®¡ç†</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("é»˜è®¤é…ç½®")
        default_config = get_default_config()
        st.json(default_config)
        
        if st.button("åº”ç”¨é»˜è®¤é…ç½®"):
            st.session_state['current_config'] = default_config
            st.success("å·²åº”ç”¨é»˜è®¤é…ç½®")
    
    with col2:
        st.subheader("é…ç½®æ¨¡æ¿")
        template = get_config_template()
        st.text_area("YAMLé…ç½®æ¨¡æ¿", template, height=400)
        
        if st.button("å¤åˆ¶æ¨¡æ¿"):
            st.success("é…ç½®æ¨¡æ¿å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")


def processing_history_page():
    """å¤„ç†å†å²é¡µé¢"""
    st.markdown('<h2 class="section-header">ğŸ“ å¤„ç†å†å²</h2>', unsafe_allow_html=True)
    
    # æ˜¾ç¤ºæœ€è¿‘çš„å¤„ç†ç»“æœ
    if 'last_result' in st.session_state:
        st.subheader("æœ€è¿‘çš„å¤„ç†ç»“æœ")
        result = st.session_state['last_result']
        
        # åŸºæœ¬ä¿¡æ¯
        processing_summary = result.get('processing_summary', {})
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å¤„ç†æ­¥éª¤", processing_summary.get('total_steps', 0))
        with col2:
            st.metric("æˆåŠŸæ­¥éª¤", processing_summary.get('successful_steps', 0))
        with col3:
            st.metric("è„±æ•å­—æ®µ", processing_summary.get('masked_columns_count', 0))
        with col4:
            st.metric("æå–ç‰¹å¾", processing_summary.get('extracted_features_count', 0))
        
        # å¤„ç†æ—¶é—´çº¿
        st.subheader("å¤„ç†æ—¶é—´çº¿")
        timeline = processing_summary.get('processing_timeline', [])
        for i, step in enumerate(timeline):
            status = step.get('status', 'unknown')
            message = step.get('message', 'æ— æ¶ˆæ¯')
            
            if status == 'success':
                st.success(f"æ­¥éª¤ {i+1}: {message}")
            elif status == 'failed':
                st.error(f"æ­¥éª¤ {i+1}: {message}")
            else:
                st.info(f"æ­¥éª¤ {i+1}: {message}")
    else:
        st.info("æš‚æ— å¤„ç†å†å²è®°å½•")


def system_status_page():
    """ç³»ç»ŸçŠ¶æ€é¡µé¢"""
    st.markdown('<h2 class="section-header">ğŸ–¥ï¸ ç³»ç»ŸçŠ¶æ€</h2>', unsafe_allow_html=True)
    
    # ç³»ç»Ÿä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Pythonç‰ˆæœ¬", f"{sys.version_info.major}.{sys.version_info.minor}")
    
    with col2:
        st.metric("Streamlitç‰ˆæœ¬", st.__version__)
    
    with col3:
        st.metric("Pandasç‰ˆæœ¬", pd.__version__)
    
    # åŠŸèƒ½çŠ¶æ€æ£€æŸ¥
    st.subheader("åŠŸèƒ½çŠ¶æ€æ£€æŸ¥")
    
    # æ£€æŸ¥å„ä¸ªæ¨¡å—
    modules_status = check_modules_status()
    
    for module_name, status in modules_status.items():
        if status:
            st.success(f"âœ… {module_name}: æ­£å¸¸")
        else:
            st.error(f"âŒ {module_name}: å¼‚å¸¸")


def check_modules_status() -> Dict[str, bool]:
    """æ£€æŸ¥æ¨¡å—çŠ¶æ€"""
    status = {}
    
    try:
        from utils.call_llm import call_llm
        status["LLMè°ƒç”¨æ¨¡å—"] = True
    except Exception:
        status["LLMè°ƒç”¨æ¨¡å—"] = False
    
    try:
        from utils.data_type_detector import detect_data_type
        status["æ•°æ®ç±»å‹æ£€æµ‹æ¨¡å—"] = True
    except Exception:
        status["æ•°æ®ç±»å‹æ£€æµ‹æ¨¡å—"] = False
    
    try:
        from utils.sensitive_detector import detect_sensitive_field
        status["æ•æ„Ÿå­—æ®µæ£€æµ‹æ¨¡å—"] = True
    except Exception:
        status["æ•æ„Ÿå­—æ®µæ£€æµ‹æ¨¡å—"] = False
    
    try:
        from utils.data_masking import mask_data
        status["æ•°æ®è„±æ•æ¨¡å—"] = True
    except Exception:
        status["æ•°æ®è„±æ•æ¨¡å—"] = False
    
    try:
        from utils.quality_metrics import calculate_quality_metrics
        status["è´¨é‡æŒ‡æ ‡æ¨¡å—"] = True
    except Exception:
        status["è´¨é‡æŒ‡æ ‡æ¨¡å—"] = False
    
    try:
        from utils.config_validator import validate_config
        status["é…ç½®éªŒè¯æ¨¡å—"] = True
    except Exception:
        status["é…ç½®éªŒè¯æ¨¡å—"] = False
    
    return status


def load_data(uploaded_file) -> pd.DataFrame:
    """åŠ è½½ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶"""
    try:
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(uploaded_file)
        elif uploaded_file.name.endswith('.json'):
            return pd.read_json(uploaded_file)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {uploaded_file.name}")
    except Exception as e:
        raise Exception(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main()
